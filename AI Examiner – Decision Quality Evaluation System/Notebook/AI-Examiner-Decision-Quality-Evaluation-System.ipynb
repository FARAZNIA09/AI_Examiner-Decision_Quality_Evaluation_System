{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c9f8ff-4af1-49e6-8940-8517dbd68932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI Examiner: Decision Quality Evaluation ===\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter scenario:  A company is experiencing declining profits and employee dissatisfaction.\n",
      "Enter decision taken:  Lay off employees immediately.\n",
      "Enter reasoning:  Laying off employees will reduce costs. This decision is obviously correct and will always improve profits. Employee concerns do not matter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Score Breakdown ---\n",
      "Logic Score: 0\n",
      "Risk Score: 0\n",
      "Bias Score: 10\n",
      "Completeness Score: 6\n",
      "Ethics Score: 20\n",
      "\n",
      "Total Score (out of 100): 36\n",
      "\n",
      "--- Explanation ---\n",
      "- Logic: Reasoning lacks clear cause–effect explanation.\n",
      "- Risk: Decision does not acknowledge possible downsides or uncertainty.\n",
      "- Bias: Reasoning is objective and neutral.\n",
      "- Completeness: Reasoning does not fully address key aspects of the scenario.\n",
      "- Ethics: No major ethical concerns detected.\n",
      "\n",
      "--- Final Verdict ---\n",
      "Verdict: Poor Decision\n",
      "Summary: Decision lacks sufficient reasoning quality and balance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14352\\1969629861.py:198: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# AI Examiner – Decision Quality Evaluation\n",
    "# ==========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "\n",
    "# ---------------- LOGIC SCORE ----------------\n",
    "def logic_score(reasoning):\n",
    "    positive_keywords = [\n",
    "        \"because\", \"therefore\", \"as a result\",\n",
    "        \"this will lead to\", \"hence\"\n",
    "    ]\n",
    "\n",
    "    negative_keywords = [\n",
    "        \"but\", \"however\", \"although\"\n",
    "    ]\n",
    "\n",
    "    reasoning_lower = reasoning.lower()\n",
    "    score = 0\n",
    "\n",
    "    for word in positive_keywords:\n",
    "        if word in reasoning_lower:\n",
    "            score += 8\n",
    "\n",
    "    for word in negative_keywords:\n",
    "        if word in reasoning_lower:\n",
    "            score -= 5\n",
    "\n",
    "    return max(0, min(score, 25))\n",
    "\n",
    "\n",
    "# ---------------- RISK SCORE ----------------\n",
    "def risk_score(reasoning):\n",
    "    risk_keywords = [\n",
    "        \"risk\", \"drawback\", \"downside\", \"challenge\",\n",
    "        \"may fail\", \"could lead to\", \"possible loss\",\n",
    "        \"uncertainty\", \"limitation\"\n",
    "    ]\n",
    "\n",
    "    reasoning_lower = reasoning.lower()\n",
    "    score = 0\n",
    "\n",
    "    for word in risk_keywords:\n",
    "        if word in reasoning_lower:\n",
    "            score += 5\n",
    "\n",
    "    return min(score, 20)\n",
    "\n",
    "\n",
    "# ---------------- BIAS SCORE ----------------\n",
    "def bias_score(reasoning):\n",
    "    absolute_words = [\n",
    "        \"always\", \"never\", \"everyone\", \"no one\", \"guaranteed\"\n",
    "    ]\n",
    "\n",
    "    emotional_words = [\n",
    "        \"obviously\", \"clearly\", \"definitely\",\n",
    "        \"best\", \"worst\", \"useless\"\n",
    "    ]\n",
    "\n",
    "    reasoning_lower = reasoning.lower()\n",
    "    score = 15  # full marks\n",
    "\n",
    "    for word in absolute_words:\n",
    "        if word in reasoning_lower:\n",
    "            score -= 3\n",
    "\n",
    "    for word in emotional_words:\n",
    "        if word in reasoning_lower:\n",
    "            score -= 2\n",
    "\n",
    "    return max(score, 0)\n",
    "\n",
    "\n",
    "# ---------------- COMPLETENESS SCORE ----------------\n",
    "def completeness_score(scenario, reasoning):\n",
    "    scenario_clean = scenario.lower().translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation)\n",
    "    )\n",
    "    reasoning_clean = reasoning.lower().translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation)\n",
    "    )\n",
    "\n",
    "    scenario_words = set(scenario_clean.split())\n",
    "    reasoning_words = set(reasoning_clean.split())\n",
    "\n",
    "    stopwords = {\n",
    "        \"the\", \"is\", \"are\", \"a\", \"an\", \"and\", \"to\", \"of\",\n",
    "        \"in\", \"on\", \"for\", \"with\", \"as\", \"by\", \"this\",\n",
    "        \"that\", \"will\", \"be\"\n",
    "    }\n",
    "\n",
    "    scenario_words -= stopwords\n",
    "    reasoning_words -= stopwords\n",
    "\n",
    "    if not scenario_words:\n",
    "        return 0\n",
    "\n",
    "    common_words = scenario_words.intersection(reasoning_words)\n",
    "    coverage_ratio = len(common_words) / len(scenario_words)\n",
    "\n",
    "    return min(int(coverage_ratio * 20), 20)\n",
    "\n",
    "\n",
    "# ---------------- ETHICS SCORE ----------------\n",
    "def ethics_score(reasoning):\n",
    "    ethical_red_flags = [\n",
    "        \"only\", \"exclude\", \"reject\", \"deny\",\n",
    "        \"prioritize younger\", \"fire\", \"terminate\",\n",
    "        \"remove support\", \"no impact\",\n",
    "        \"does not matter\", \"irrelevant\"\n",
    "    ]\n",
    "\n",
    "    reasoning_lower = reasoning.lower()\n",
    "    score = 20  # full marks\n",
    "\n",
    "    for word in ethical_red_flags:\n",
    "        if word in reasoning_lower:\n",
    "            score -= 4\n",
    "\n",
    "    return max(score, 0)\n",
    "\n",
    "\n",
    "# ---------------- SCORE DECISION ----------------\n",
    "def score_decision(decision_data):\n",
    "    return {\n",
    "        \"logic\": logic_score(decision_data[\"reasoning\"]),\n",
    "        \"risk\": risk_score(decision_data[\"reasoning\"]),\n",
    "        \"bias\": bias_score(decision_data[\"reasoning\"]),\n",
    "        \"completeness\": completeness_score(\n",
    "            decision_data[\"scenario\"],\n",
    "            decision_data[\"reasoning\"]\n",
    "        ),\n",
    "        \"ethics\": ethics_score(decision_data[\"reasoning\"])\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------- EXPLANATION ----------------\n",
    "def generate_explanation(scores):\n",
    "    explanations = []\n",
    "\n",
    "    explanations.append(\n",
    "        \"Logic: Reasoning lacks clear cause–effect explanation.\"\n",
    "        if scores[\"logic\"] < 10\n",
    "        else \"Logic: Reasoning shows acceptable cause–effect clarity.\"\n",
    "    )\n",
    "\n",
    "    explanations.append(\n",
    "        \"Risk: Decision does not acknowledge possible downsides or uncertainty.\"\n",
    "        if scores[\"risk\"] < 5\n",
    "        else \"Risk: Decision considers potential risks.\"\n",
    "    )\n",
    "\n",
    "    explanations.append(\n",
    "        \"Bias: Reasoning contains emotionally loaded or absolute language.\"\n",
    "        if scores[\"bias\"] < 10\n",
    "        else \"Bias: Reasoning is objective and neutral.\"\n",
    "    )\n",
    "\n",
    "    explanations.append(\n",
    "        \"Completeness: Reasoning does not fully address key aspects of the scenario.\"\n",
    "        if scores[\"completeness\"] < 8\n",
    "        else \"Completeness: Reasoning sufficiently addresses the scenario.\"\n",
    "    )\n",
    "\n",
    "    explanations.append(\n",
    "        \"Ethics: Decision may unfairly impact certain stakeholders.\"\n",
    "        if scores[\"ethics\"] < 10\n",
    "        else \"Ethics: No major ethical concerns detected.\"\n",
    "    )\n",
    "\n",
    "    return explanations\n",
    "\n",
    "\n",
    "# ---------------- VERDICT ----------------\n",
    "def decision_verdict(total_score):\n",
    "    if total_score >= 60:\n",
    "        return \"Good Decision\", \"Reasoning is strong, balanced, and well-considered.\"\n",
    "    elif total_score >= 40:\n",
    "        return \"Risky Decision\", \"Decision has merit but shows notable weaknesses.\"\n",
    "    else:\n",
    "        return \"Poor Decision\", \"Decision lacks sufficient reasoning quality and balance.\"\n",
    "\n",
    "\n",
    "# ---------------- VISUALIZATION ----------------\n",
    "def visualize_scores(scores):\n",
    "    dimensions = list(scores.keys())\n",
    "    values = list(scores.values())\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(dimensions, values)\n",
    "    plt.ylim(0, 25)\n",
    "    plt.xlabel(\"Evaluation Dimensions\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Decision Quality Breakdown\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def main():\n",
    "    print(\"=== AI Examiner: Decision Quality Evaluation ===\\n\")\n",
    "\n",
    "    decision_data = {\n",
    "        \"scenario\": input(\"Enter scenario: \"),\n",
    "        \"decision\": input(\"Enter decision taken: \"),\n",
    "        \"reasoning\": input(\"Enter reasoning: \")\n",
    "    }\n",
    "\n",
    "    scores = score_decision(decision_data)\n",
    "\n",
    "    print(\"\\n--- Score Breakdown ---\")\n",
    "    for key, value in scores.items():\n",
    "        print(f\"{key.capitalize()} Score: {value}\")\n",
    "\n",
    "    total_score = sum(scores.values())\n",
    "    print(\"\\nTotal Score (out of 100):\", total_score)\n",
    "\n",
    "    explanations = generate_explanation(scores)\n",
    "\n",
    "    print(\"\\n--- Explanation ---\")\n",
    "    for exp in explanations:\n",
    "        print(\"-\", exp)\n",
    "\n",
    "    verdict, verdict_reason = decision_verdict(total_score)\n",
    "\n",
    "    print(\"\\n--- Final Verdict ---\")\n",
    "    print(\"Verdict:\", verdict)\n",
    "    print(\"Summary:\", verdict_reason)\n",
    "\n",
    "    visualize_scores(scores)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21dc19b-1b5c-4be5-9dca-5f2041774a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
